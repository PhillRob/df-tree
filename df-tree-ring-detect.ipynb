{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os, rasterio\n",
    "import time\n",
    "from deepforest import main, utilities, get_data, preprocess \n",
    "from os.path import exists\n",
    "from  PIL import Image, ImagePath\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('R', 'G', 'B')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = get_data(\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\img\\\\DQ_2022_3b.tif\")\n",
    "print(exists(image_path))\n",
    "\n",
    "# annotations = (\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\annotation\\\\deep-forest-training.csv\")\n",
    "# print(exists(annotations))\n",
    "\n",
    "exImg=Image.open(image_path)\n",
    "exImg.getbands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_shp=\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\annotation\\\\deep-forest-training.shp\"\n",
    "annotations=utilities.shapefile_to_annotations(ano_shp, image_path,  savedir='.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations.to_csv(\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\annotation\\\\deep-forest-training-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_csv=r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\crop\\DQ_2022_3b.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write csv to file and crop\n",
    "tmpdir = (\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\crop\\\\\")\n",
    "# annotations.to_csv(\"{}/example.csv\".format(tmpdir), index=False)\n",
    "annotations_file = preprocess.split_raster(path_to_raster=image_path,\n",
    "                                           annotations_file=ano_csv,\n",
    "                                           base_dir=tmpdir,\n",
    "                                           patch_size=500,\n",
    "                                           patch_overlap=0.25)\n",
    "\n",
    "# Returns a 6 column pandas array\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(annotations_file['Unnamed: 0'])\n",
    "assert annotations_file.shape[1] == 6\n",
    "annotations_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ano_split=get_data(r\"D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\07 Temp\\Hankos_Submittals\\221001_DQ_ECW2022\\crop\\DQ_2022_3b.csv\")\n",
    "exists(ano_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\crop\\\\DQ_2022_3b.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ano_split\n",
    "# os.path.dirname(ano_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading config file: c:\\Users\\Robeck\\anaconda3\\envs\\df-tree\\lib\\site-packages\\deepforest\\data\\deepforest_config.yml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\anaconda3\\envs\\df-tree\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Robeck\\anaconda3\\envs\\df-tree\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=RetinaNet_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=RetinaNet_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model from DeepForest release https://github.com/weecology/DeepForest/releases/tag/1.0.0 was already downloaded. Loading model from file.\n",
      "Loading pre-built model: https://github.com/weecology/DeepForest/releases/tag/1.0.0\n"
     ]
    }
   ],
   "source": [
    "model = main.deepforest()\n",
    "\n",
    "# Example run with short training\n",
    "model.config[\"train\"]['epochs'] = 5\n",
    "# model.config['gpus'] = '-1' #move to GPU and use all the GPU resources\n",
    "# model.config['cpu'] = 'accelerator'\n",
    "model.config[\"save-snapshot\"] = False\n",
    "model.config[\"train\"][\"csv_file\"] = ano_split\n",
    "model.config[\"train\"][\"root_dir\"] = os.path.dirname(ano_split)\n",
    "model.config['num_worker']=16\n",
    "# model.config['max_epochs']=10\n",
    "model.create_trainer()\n",
    "model.use_release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type      | Params\n",
      "------------------------------------\n",
      "0 | model | RetinaNet | 32.1 M\n",
      "------------------------------------\n",
      "31.9 M    Trainable params\n",
      "222 K     Non-trainable params\n",
      "32.1 M    Total params\n",
      "128.592   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9bbfebe55fb4bb39f0be4ca695cb91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robeck\\anaconda3\\envs\\df-tree\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:366: UserWarning: One of given dataloaders is None and it will be skipped.\n",
      "  rank_zero_warn(\"One of given dataloaders is None and it will be skipped.\")\n",
      "c:\\Users\\Robeck\\anaconda3\\envs\\df-tree\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d011401e3f74199a5ea2a124c56d7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training on CPU: 1214.79 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model.trainer.fit(model)\n",
    "print(f\"--- Training on CPU: {(time.time() - start_time):.2f} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1302/1302 [24:26<00:00,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No predictions made, returning None\n",
      "No predictions made, returning None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# boxes = model.predict_image(path=image_path, return_plot = True)\n",
    "predicted_raster = model.predict_tile(image_path, return_plot = False, patch_size=500,patch_overlap=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(predicted_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rasterio.open(image_path)\n",
    "transform = r.transform \n",
    "crs = r.crs\n",
    "print(crs)\n",
    "\n",
    "gdf = utilities.annotations_to_shapefile(predicted_raster, transform=transform, crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('trained-500-1e.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Image class from PIL module\n",
    " \n",
    "# Opens a image in RGB mode\n",
    "RUH_img = Image.open(r\"\\\\?\\D:\\Dropbox\\P.Robeck\\BPLA Dropbox\\08 GIS-data\\GIS-data-Riyadh\\2022-03-world-view-3\\RCRC-4Bands-Mosaic_FIN_I542628_614813\\RCRC-4Bands-Mosaic_FIN_I542628_614813\\RCRC-4Bands-Mosaic_I542628_FL01-P244705\\RCRC-4Bands-Mosaic_MOS\\22FEB15073634-S2AM-RCRC-4Bands-Mosaic.TIF\")\n",
    "\n",
    "DQ_img = Image.open(r\"D:\\\\Dropbox\\\\P.Robeck\\\\BPLA Dropbox\\\\07 Temp\\\\Hankos_Submittals\\\\221001_DQ_ECW2022\\\\PNG\\\\DQ_2022_3b.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DQ_img.getbbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DQ_img.format, DQ_img.size, DQ_img.mode,DQ_img.getbbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('df-tree')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48610190cd9e48a9b8fe506a8d1704d51ddc79aecac44894f53e1a7932d85bf8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
